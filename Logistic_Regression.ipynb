{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0sHEyQL9psgLdYG5uhg5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvinfoo123/PyTorch_Projects/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "utnXTcEXKJ_A"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import numpy as np \n",
        "from sklearn import datasets \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import train_test_split "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset \n",
        "bc = datasets.load_breast_cancer()\n",
        "X,y = bc.data, bc.target \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "cKcNefqtKZ3o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale dataset \n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to tensor \n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0],1) # Change y into column tensor \n",
        "y_test = y_test.view(y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "SaJtLatGKuB1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model \n",
        "n_input_features = X.shape[1]\n",
        "\n",
        "class LogisticRegression(nn.Module): \n",
        "\n",
        "  def __init__(self, n_input_features): \n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self, x): \n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted \n",
        "\n",
        "model = LogisticRegression(n_input_features)"
      ],
      "metadata": {
        "id": "iqziuICBLcmE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer \n",
        "learning_rate = 0.01 \n",
        "criterion = nn.BCELoss() # Binary cross entropy loss \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "nErumm1ZOP3q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training \n",
        "num_epochs = 100 \n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "  # Forward pass\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "  \n",
        "  # Backward pass \n",
        "  loss.backward()\n",
        "\n",
        "  # Update \n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  [w,b] = model.parameters()\n",
        "  print(f'epoch {epoch + 1}: w ={w[0][0].item():.3f}, loss = {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC9taM5MOoUG",
        "outputId": "966ad9e5-28a5-4e5c-b7ba-70830a0fe54a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w =0.123, loss = 0.7984\n",
            "epoch 2: w =0.119, loss = 0.7740\n",
            "epoch 3: w =0.115, loss = 0.7508\n",
            "epoch 4: w =0.112, loss = 0.7289\n",
            "epoch 5: w =0.108, loss = 0.7081\n",
            "epoch 6: w =0.104, loss = 0.6884\n",
            "epoch 7: w =0.101, loss = 0.6698\n",
            "epoch 8: w =0.097, loss = 0.6523\n",
            "epoch 9: w =0.094, loss = 0.6356\n",
            "epoch 10: w =0.091, loss = 0.6199\n",
            "epoch 11: w =0.087, loss = 0.6050\n",
            "epoch 12: w =0.084, loss = 0.5910\n",
            "epoch 13: w =0.081, loss = 0.5776\n",
            "epoch 14: w =0.078, loss = 0.5650\n",
            "epoch 15: w =0.075, loss = 0.5531\n",
            "epoch 16: w =0.073, loss = 0.5418\n",
            "epoch 17: w =0.070, loss = 0.5311\n",
            "epoch 18: w =0.067, loss = 0.5209\n",
            "epoch 19: w =0.065, loss = 0.5112\n",
            "epoch 20: w =0.062, loss = 0.5020\n",
            "epoch 21: w =0.059, loss = 0.4932\n",
            "epoch 22: w =0.057, loss = 0.4849\n",
            "epoch 23: w =0.055, loss = 0.4769\n",
            "epoch 24: w =0.052, loss = 0.4693\n",
            "epoch 25: w =0.050, loss = 0.4620\n",
            "epoch 26: w =0.048, loss = 0.4551\n",
            "epoch 27: w =0.046, loss = 0.4484\n",
            "epoch 28: w =0.043, loss = 0.4420\n",
            "epoch 29: w =0.041, loss = 0.4359\n",
            "epoch 30: w =0.039, loss = 0.4300\n",
            "epoch 31: w =0.037, loss = 0.4244\n",
            "epoch 32: w =0.035, loss = 0.4189\n",
            "epoch 33: w =0.033, loss = 0.4137\n",
            "epoch 34: w =0.031, loss = 0.4087\n",
            "epoch 35: w =0.029, loss = 0.4038\n",
            "epoch 36: w =0.027, loss = 0.3991\n",
            "epoch 37: w =0.026, loss = 0.3946\n",
            "epoch 38: w =0.024, loss = 0.3902\n",
            "epoch 39: w =0.022, loss = 0.3860\n",
            "epoch 40: w =0.020, loss = 0.3819\n",
            "epoch 41: w =0.019, loss = 0.3780\n",
            "epoch 42: w =0.017, loss = 0.3741\n",
            "epoch 43: w =0.015, loss = 0.3704\n",
            "epoch 44: w =0.014, loss = 0.3668\n",
            "epoch 45: w =0.012, loss = 0.3634\n",
            "epoch 46: w =0.010, loss = 0.3600\n",
            "epoch 47: w =0.009, loss = 0.3567\n",
            "epoch 48: w =0.007, loss = 0.3535\n",
            "epoch 49: w =0.006, loss = 0.3504\n",
            "epoch 50: w =0.004, loss = 0.3474\n",
            "epoch 51: w =0.003, loss = 0.3444\n",
            "epoch 52: w =0.001, loss = 0.3416\n",
            "epoch 53: w =-0.000, loss = 0.3388\n",
            "epoch 54: w =-0.002, loss = 0.3361\n",
            "epoch 55: w =-0.003, loss = 0.3334\n",
            "epoch 56: w =-0.004, loss = 0.3308\n",
            "epoch 57: w =-0.006, loss = 0.3283\n",
            "epoch 58: w =-0.007, loss = 0.3259\n",
            "epoch 59: w =-0.008, loss = 0.3235\n",
            "epoch 60: w =-0.010, loss = 0.3211\n",
            "epoch 61: w =-0.011, loss = 0.3188\n",
            "epoch 62: w =-0.012, loss = 0.3166\n",
            "epoch 63: w =-0.014, loss = 0.3144\n",
            "epoch 64: w =-0.015, loss = 0.3123\n",
            "epoch 65: w =-0.016, loss = 0.3102\n",
            "epoch 66: w =-0.017, loss = 0.3082\n",
            "epoch 67: w =-0.019, loss = 0.3062\n",
            "epoch 68: w =-0.020, loss = 0.3042\n",
            "epoch 69: w =-0.021, loss = 0.3023\n",
            "epoch 70: w =-0.022, loss = 0.3004\n",
            "epoch 71: w =-0.023, loss = 0.2986\n",
            "epoch 72: w =-0.025, loss = 0.2968\n",
            "epoch 73: w =-0.026, loss = 0.2950\n",
            "epoch 74: w =-0.027, loss = 0.2932\n",
            "epoch 75: w =-0.028, loss = 0.2915\n",
            "epoch 76: w =-0.029, loss = 0.2899\n",
            "epoch 77: w =-0.030, loss = 0.2882\n",
            "epoch 78: w =-0.031, loss = 0.2866\n",
            "epoch 79: w =-0.032, loss = 0.2850\n",
            "epoch 80: w =-0.033, loss = 0.2835\n",
            "epoch 81: w =-0.035, loss = 0.2820\n",
            "epoch 82: w =-0.036, loss = 0.2805\n",
            "epoch 83: w =-0.037, loss = 0.2790\n",
            "epoch 84: w =-0.038, loss = 0.2776\n",
            "epoch 85: w =-0.039, loss = 0.2761\n",
            "epoch 86: w =-0.040, loss = 0.2747\n",
            "epoch 87: w =-0.041, loss = 0.2734\n",
            "epoch 88: w =-0.042, loss = 0.2720\n",
            "epoch 89: w =-0.043, loss = 0.2707\n",
            "epoch 90: w =-0.044, loss = 0.2694\n",
            "epoch 91: w =-0.045, loss = 0.2681\n",
            "epoch 92: w =-0.046, loss = 0.2668\n",
            "epoch 93: w =-0.047, loss = 0.2656\n",
            "epoch 94: w =-0.048, loss = 0.2643\n",
            "epoch 95: w =-0.048, loss = 0.2631\n",
            "epoch 96: w =-0.049, loss = 0.2619\n",
            "epoch 97: w =-0.050, loss = 0.2608\n",
            "epoch 98: w =-0.051, loss = 0.2596\n",
            "epoch 99: w =-0.052, loss = 0.2585\n",
            "epoch 100: w =-0.053, loss = 0.2573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation \n",
        "with torch.no_grad(): \n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_class = y_predicted.round() # 1 if sigmoid is 0.5 or larger and 0 otherwise \n",
        "  accuracy = y_predicted_class.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy = {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObmezQVcPGs6",
        "outputId": "67429fb6-9711-455f-fc57-09728b29526f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.9649\n"
          ]
        }
      ]
    }
  ]
}